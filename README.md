<img src="https://github.com/moritzmitterdorfer/TarantulaNN/blob/master/imgs/logo.png">

# TarantulaNN
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

ðŸ•·ðŸ•¸ Implementation of a Deep Neural Network with flexibles architectures and activation functions

<br>

## Layers:

- FullyConnectedLayer

## Activation functions:

- ReLU (*, Rectified Linear Unit)
- Sigmoid
- Tanh

## Training:

- mini-batch gradient descent
- stochastic gradient descent

## Cost function:

- Sum of squares

## License
This project is licensed under the terms of the MIT license, see LICENSE.
